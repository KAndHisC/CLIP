{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53N4k0pj_9qL"
      },
      "source": [
        "# Preparation for Colab\n",
        "\n",
        "Make sure you're running a GPU runtime; if not, select \"GPU\" as the hardware accelerator in Runtime > Change Runtime Type in the menu. The next cells will install the `clip` package and its dependencies, and check if PyTorch 1.7.1 or later is installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BpdJkdBssk9",
        "outputId": "41a4070f-5321-4fc4-bd4d-0b5c1f476d56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ftfy\n",
            "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████                           | 10 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20 kB 18.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 40 kB 4.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 51 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 61 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 64 kB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy) (0.2.5)\n",
            "Building wheels for collected packages: ftfy\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41934 sha256=90ec193331444b2c4ff1cd81935e7de42065b89d304db7efac67bcfd87c27873\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n",
            "Successfully built ftfy\n",
            "Installing collected packages: ftfy\n",
            "Successfully installed ftfy-6.0.3\n",
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-hqnbveqi\n",
            "  Running command git clone -q https://github.com/openai/CLIP.git /tmp/pip-req-build-hqnbveqi\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (6.0.3)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (4.41.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (1.9.0+cu102)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (0.10.0+cu102)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->clip==1.0) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->clip==1.0) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (1.19.5)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->clip==1.0) (7.1.2)\n",
            "Building wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369080 sha256=fda43d2b80cfb2b33c2d43e23ea5f53293a9a8b48d5f9e341de527f6adfbf5a3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-kmmplf44/wheels/fd/b9/c3/5b4470e35ed76e174bff77c92f91da82098d5e35fd5bc8cdac\n",
            "Successfully built clip\n",
            "Installing collected packages: clip\n",
            "Successfully installed clip-1.0\n"
          ]
        }
      ],
      "source": [
        "# ! pip install ftfy regex tqdm\n",
        "# ! pip install git+https://github.com/openai/CLIP.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1hkDT38hSaP",
        "outputId": "e10d4f17-8fa6-4b75-a18f-f0c38990b5a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Torch version: 1.9.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import clip\n",
        "# from tqdm.notebook import tqdm\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"Torch version:\", torch.__version__)\n",
        "\n",
        "assert torch.__version__.split(\".\") >= [\"1\", \"7\", \"1\"], \"PyTorch 1.7.1 or later is required\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFxgLV5HAEEw"
      },
      "source": [
        "# Loading the model\n",
        "\n",
        "Download and instantiate a CLIP model using the `clip` module that we just installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLFS29hnhlY4",
        "outputId": "09abb234-693e-4efb-953f-e1847ba95758"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['RN50', 'RN101', 'RN50x4', 'RN50x16', 'ViT-B/32', 'ViT-B/16']\n",
            "/localdata/workspace/CLIP/notebooks\n"
          ]
        }
      ],
      "source": [
        "print(clip.available_models())\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cboKZocQlSYX",
        "outputId": "240acdd0-ca62-45db-8418-9e4ef73e8aff"
      },
      "outputs": [],
      "source": [
        "# model, preprocess = clip.load(\"ViT-B/32\")\n",
        "model, preprocess = clip.load(\"../models/200m0.988.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBRVTY9lbGm8",
        "outputId": "785019a1-1f40-45b0-e349-b0d4ec3173bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model parameters: 151,277,313\n",
            "Input resolution: 224\n",
            "Context length: 77\n",
            "Vocab size: 49408\n"
          ]
        }
      ],
      "source": [
        "input_resolution = model.visual.input_resolution\n",
        "context_length = model.context_length\n",
        "vocab_size = model.vocab_size\n",
        "\n",
        "print(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\")\n",
        "print(\"Input resolution:\", input_resolution)\n",
        "print(\"Context length:\", context_length)\n",
        "print(\"Vocab size:\", vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhO3OtOmF8M4"
      },
      "source": [
        "# Preparing ImageNet labels and prompts\n",
        "\n",
        "The following cell contains the 1,000 labels for the ImageNet dataset, followed by the text templates we'll use as \"prompt engineering\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "R2HbOZrqa0jF"
      },
      "outputs": [],
      "source": [
        "classes = [\n",
        "    'apple',\n",
        "    'aquarium fish',\n",
        "    'baby',\n",
        "    'bear',\n",
        "    'beaver',\n",
        "    'bed',\n",
        "    'bee',\n",
        "    'beetle',\n",
        "    'bicycle',\n",
        "    'bottle',\n",
        "    'bowl',\n",
        "    'boy',\n",
        "    'bridge',\n",
        "    'bus',\n",
        "    'butterfly',\n",
        "    'camel',\n",
        "    'can',\n",
        "    'castle',\n",
        "    'caterpillar',\n",
        "    'cattle',\n",
        "    'chair',\n",
        "    'chimpanzee',\n",
        "    'clock',\n",
        "    'cloud',\n",
        "    'cockroach',\n",
        "    'couch',\n",
        "    'crab',\n",
        "    'crocodile',\n",
        "    'cup',\n",
        "    'dinosaur',\n",
        "    'dolphin',\n",
        "    'elephant',\n",
        "    'flatfish',\n",
        "    'forest',\n",
        "    'fox',\n",
        "    'girl',\n",
        "    'hamster',\n",
        "    'house',\n",
        "    'kangaroo',\n",
        "    'keyboard',\n",
        "    'lamp',\n",
        "    'lawn mower',\n",
        "    'leopard',\n",
        "    'lion',\n",
        "    'lizard',\n",
        "    'lobster',\n",
        "    'man',\n",
        "    'maple tree',\n",
        "    'motorcycle',\n",
        "    'mountain',\n",
        "    'mouse',\n",
        "    'mushroom',\n",
        "    'oak tree',\n",
        "    'orange',\n",
        "    'orchid',\n",
        "    'otter',\n",
        "    'palm tree',\n",
        "    'pear',\n",
        "    'pickup truck',\n",
        "    'pine tree',\n",
        "    'plain',\n",
        "    'plate',\n",
        "    'poppy',\n",
        "    'porcupine',\n",
        "    'possum',\n",
        "    'rabbit',\n",
        "    'raccoon',\n",
        "    'ray',\n",
        "    'road',\n",
        "    'rocket',\n",
        "    'rose',\n",
        "    'sea',\n",
        "    'seal',\n",
        "    'shark',\n",
        "    'shrew',\n",
        "    'skunk',\n",
        "    'skyscraper',\n",
        "    'snail',\n",
        "    'snake',\n",
        "    'spider',\n",
        "    'squirrel',\n",
        "    'streetcar',\n",
        "    'sunflower',\n",
        "    'sweet pepper',\n",
        "    'table',\n",
        "    'tank',\n",
        "    'telephone',\n",
        "    'television',\n",
        "    'tiger',\n",
        "    'tractor',\n",
        "    'train',\n",
        "    'trout',\n",
        "    'tulip',\n",
        "    'turtle',\n",
        "    'wardrobe',\n",
        "    'whale',\n",
        "    'willow tree',\n",
        "    'wolf',\n",
        "    'woman',\n",
        "    'worm',\n",
        "]\n",
        "\n",
        "templates = [\n",
        "    'a photo of a {}.',\n",
        "    'a blurry photo of a {}.',\n",
        "    'a black and white photo of a {}.',\n",
        "    'a low contrast photo of a {}.',\n",
        "    'a high contrast photo of a {}.',\n",
        "    'a bad photo of a {}.',\n",
        "    'a good photo of a {}.',\n",
        "    'a photo of a small {}.',\n",
        "    'a photo of a big {}.',\n",
        "    'a photo of the {}.',\n",
        "    'a blurry photo of the {}.',\n",
        "    'a black and white photo of the {}.',\n",
        "    'a low contrast photo of the {}.',\n",
        "    'a high contrast photo of the {}.',\n",
        "    'a bad photo of the {}.',\n",
        "    'a good photo of the {}.',\n",
        "    'a photo of the small {}.',\n",
        "    'a photo of the big {}.',\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMQSCuBta2G6"
      },
      "source": [
        "A subset of these class names are modified from the default ImageNet class names sourced from Anish Athalye's imagenet-simple-labels.\n",
        "\n",
        "These edits were made via trial and error and concentrated on the lowest performing classes according to top_1 and top_5 accuracy on the ImageNet training set for the RN50, RN101, and RN50x4 models. These tweaks improve top_1 by 1.5% on ViT-B/32 over using the default class names. Alec got bored somewhere along the way as gains started to diminish and never finished updating / tweaking the list. He also didn't revisit this with the better performing RN50x16, RN50x64, or any of the ViT models. He thinks it's likely another 0.5% to 1% top_1 could be gained from further work here. It'd be interesting to more rigorously study / understand this.\n",
        "\n",
        "Some examples beyond the crane/crane -> construction crane / bird crane issue mentioned in Section 3.1.4 of the paper include:\n",
        "\n",
        "- CLIP interprets \"nail\" as \"fingernail\" so we changed the label to \"metal nail\".\n",
        "- ImageNet kite class refers to the bird of prey, not the flying toy, so we changed \"kite\" to \"kite (bird of prey)\"\n",
        "- The ImageNet class for red wolf seems to include a lot of mislabeled maned wolfs so we changed \"red wolf\" to \"red wolf or maned wolf\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toGtcd-Ji_MD",
        "outputId": "b6eb0753-2bee-4144-abe3-fbd23f35f555"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100 classes, 18 templates\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "print(f\"{len(classes)} classes, {len(templates)} templates\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRB5OzgpHwqQ"
      },
      "source": [
        "A similar, intuition-guided trial and error based on the ImageNet training set was used for templates. This list is pretty haphazard and was gradually made / expanded over the course of about a year of the project and was revisited / tweaked every few months. A surprising / weird thing was adding templates intended to help ImageNet-R performance (specifying different possible renditions of an object) improved standard ImageNet accuracy too.\n",
        "\n",
        "After the 80 templates were \"locked\" for the paper, we ran sequential forward selection over the list of 80 templates. The search terminated after ensembling 7 templates and selected them in the order below.\n",
        "\n",
        "1. itap of a {}.\n",
        "2. a bad photo of the {}.\n",
        "3. a origami {}.\n",
        "4. a photo of the large {}.\n",
        "5. a {} in a video game.\n",
        "6. art of the {}.\n",
        "7. a photo of the small {}.\n",
        "\n",
        "Speculating, we think it's interesting to see different scales (large and small), a difficult view (a bad photo), and \"abstract\" versions (origami, video game, art), were all selected for, but we haven't studied this in any detail. This subset performs a bit better than the full 80 ensemble reported in the paper, especially for the smaller models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4W8ARJVqBJXs"
      },
      "source": [
        "# Loading the Images\n",
        "\n",
        "The ILSVRC2012 datasets are no longer available for download publicly. We instead download the ImageNet-V2 dataset by [Recht et al.](https://arxiv.org/abs/1902.10811).\n",
        "\n",
        "If you have the ImageNet dataset downloaded, you can replace the dataset with the official torchvision loader, e.g.:\n",
        "\n",
        "```python\n",
        "images = torchvision.datasets.ImageNet(\"path/to/imagenet\", split='val', transform=preprocess)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moHR4UlHKsDc",
        "outputId": "40731297-edc7-4cd0-be75-ed426c8fb005"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# ! pip install git+https://github.com/modestyachts/ImageNetV2_pytorch\n",
        "\n",
        "# from imagenetv2_pytorch import ImageNetV2Dataset\n",
        "\n",
        "# images = ImageNetV2Dataset(transform=preprocess)\n",
        "\n",
        "from torchvision.datasets import CIFAR100\n",
        "import os\n",
        "cifar100 = CIFAR100(root=os.path.expanduser(\"./data/cifar100\"), download=True, train=True, transform=preprocess)\n",
        "\n",
        "loader = torch.utils.data.DataLoader(cifar100, batch_size=32, num_workers=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fz6D-F-Wbrtp"
      },
      "source": [
        "# Creating zero-shot classifier weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "66a1639713ae441d8a9b873381f9d774",
            "610b775178c645e2b4663b77cc0c67b6",
            "412dd15f0d8542f5ab2730f8616fb582",
            "5e6315f36b4e4eeea5c6294b024e0c97",
            "085d5388abda4202bfa66d0c088452f8",
            "f75124b64aa147c693c67a78f8e3a231",
            "6e5676a054874243b55fc6d120a07d01",
            "dc6d1416c01a4047935ee15c3fd2eb1c"
          ]
        },
        "id": "sRqDoz1Gbsii",
        "outputId": "312b8ebf-3961-4903-d8cb-3b7a94cc97b6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 74.94it/s]\n"
          ]
        }
      ],
      "source": [
        "def zeroshot_classifier(classnames, templates):\n",
        "    with torch.no_grad():\n",
        "        zeroshot_weights = []\n",
        "        for classname in tqdm(classnames):\n",
        "            texts = [template.format(classname) for template in templates] #format with class\n",
        "            texts = clip.tokenize(texts).cuda() #tokenize\n",
        "            class_embeddings = model.encode_text(texts) #embed with text encoder\n",
        "            class_embeddings /= class_embeddings.norm(dim=-1, keepdim=True)\n",
        "            class_embedding = class_embeddings.mean(dim=0)\n",
        "            class_embedding /= class_embedding.norm()\n",
        "            zeroshot_weights.append(class_embedding)\n",
        "        zeroshot_weights = torch.stack(zeroshot_weights, dim=1).cuda()\n",
        "    return zeroshot_weights\n",
        "\n",
        "\n",
        "zeroshot_weights = zeroshot_classifier(classes, templates)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fZo7hG8iJP5"
      },
      "source": [
        "# Zero-shot prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "j4kPSZoShQxN"
      },
      "outputs": [],
      "source": [
        "def accuracy(output, target, topk=(1,)):\n",
        "    pred = output.topk(max(topk), 1, True, True)[1].t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "    return [float(correct[:k].reshape(-1).float().sum(0, keepdim=True).cpu().numpy()) for k in topk]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102,
          "referenced_widgets": [
            "84f80a7f3e764346969a347b0f71b24e",
            "392656f01b2945f3bd7903783ed8cc96",
            "8e47a435519b4ce090879b4be2f61f99",
            "41b1ed6b0a9745c1a595377670b15ff4",
            "179b8ae1eb7f4a828f953e889b141725",
            "d8708e8414fd44f4abd6590c9b57996f",
            "800e30f5b4f24475a2b0046da0703631",
            "8764308b948745f1a677332fd21fcaf0"
          ]
        },
        "id": "wKJ7YsdlkDXo",
        "outputId": "ab824854-38e4-4d37-ad40-2a7ce3c5fd43"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1563/1563 [00:43<00:00, 35.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-1 accuracy: 12.53\n",
            "Top-5 accuracy: 35.51\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    top1, top5, n = 0., 0., 0.\n",
        "    for i, (images, target) in enumerate(tqdm(loader)):\n",
        "        images = images.cuda()\n",
        "        target = target.cuda()\n",
        "        \n",
        "        # predict\n",
        "        image_features = model.encode_image(images)\n",
        "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "        logits = 100. * image_features @ zeroshot_weights\n",
        "\n",
        "        # measure accuracy\n",
        "        acc1, acc5 = accuracy(logits, target, topk=(1, 5))\n",
        "        top1 += acc1\n",
        "        top5 += acc5\n",
        "        n += images.size(0)\n",
        "\n",
        "top1 = (top1 / n) * 100\n",
        "top5 = (top5 / n) * 100 \n",
        "\n",
        "print(f\"Top-1 accuracy: {top1:.2f}\")\n",
        "print(f\"Top-5 accuracy: {top5:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Prompt Engineering for ImageNet.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "dbdf44c3cb1c202bcde82d270ec00c561ec790b1cd8e864021d409a0c070b1bd"
    },
    "kernelspec": {
      "display_name": "Python 3.6.13 64-bit ('clip': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "085d5388abda4202bfa66d0c088452f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "179b8ae1eb7f4a828f953e889b141725": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "392656f01b2945f3bd7903783ed8cc96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "412dd15f0d8542f5ab2730f8616fb582": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f75124b64aa147c693c67a78f8e3a231",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_085d5388abda4202bfa66d0c088452f8",
            "value": 1000
          }
        },
        "41b1ed6b0a9745c1a595377670b15ff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8764308b948745f1a677332fd21fcaf0",
            "placeholder": "​",
            "style": "IPY_MODEL_800e30f5b4f24475a2b0046da0703631",
            "value": " 313/313 [02:31&lt;00:00,  2.07it/s]"
          }
        },
        "5e6315f36b4e4eeea5c6294b024e0c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc6d1416c01a4047935ee15c3fd2eb1c",
            "placeholder": "​",
            "style": "IPY_MODEL_6e5676a054874243b55fc6d120a07d01",
            "value": " 1000/1000 [16:51&lt;00:00,  1.01s/it]"
          }
        },
        "610b775178c645e2b4663b77cc0c67b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66a1639713ae441d8a9b873381f9d774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_412dd15f0d8542f5ab2730f8616fb582",
              "IPY_MODEL_5e6315f36b4e4eeea5c6294b024e0c97"
            ],
            "layout": "IPY_MODEL_610b775178c645e2b4663b77cc0c67b6"
          }
        },
        "6e5676a054874243b55fc6d120a07d01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "800e30f5b4f24475a2b0046da0703631": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84f80a7f3e764346969a347b0f71b24e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e47a435519b4ce090879b4be2f61f99",
              "IPY_MODEL_41b1ed6b0a9745c1a595377670b15ff4"
            ],
            "layout": "IPY_MODEL_392656f01b2945f3bd7903783ed8cc96"
          }
        },
        "8764308b948745f1a677332fd21fcaf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e47a435519b4ce090879b4be2f61f99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8708e8414fd44f4abd6590c9b57996f",
            "max": 313,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_179b8ae1eb7f4a828f953e889b141725",
            "value": 313
          }
        },
        "d8708e8414fd44f4abd6590c9b57996f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc6d1416c01a4047935ee15c3fd2eb1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f75124b64aa147c693c67a78f8e3a231": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
